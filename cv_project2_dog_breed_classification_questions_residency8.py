# -*- coding: utf-8 -*-
"""CV_Project2_Dog_Breed_Classification_Questions_Residency8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-hKKgCI-IQwcSDtsp2dqEWlboAId1PRc

## Dog Breed Classification

In this project we will use traditional CNN, CNN with data augmentation and finally transfer Learning by VGG16 model with weights pre-trained on Imagenet to solve the dog breed classification problem

### Load Dataset Files
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
print(tf.__version__)

from google.colab import drive
import pandas as pd
import numpy as np
from tqdm import tqdm
import cv2
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
#Importing required keras modules
from tensorflow.keras.models import Sequential
from tensorflow.keras.backend import clear_session
from tensorflow.keras.layers import Reshape, Dense, Dropout, BatchNormalization, Activation, Conv2D, MaxPool2D, Flatten
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input

drive.mount('/content/drive/')

"""Now, upload the given dataset file shared with you in your google drive and give its path for the below given `project_path` variable. For example, a path is given below according to the file path in our google drive. You need to change this to match the path of yours."""

project_path = "/content/drive/My Drive/GreatLearning/myprojects/Residency8/DogBreed_Classification/"

"""Run the below code to extract all the images in the train.zip files given in the dataset. We are going to use these images as train and validation sets and their labels in further steps."""

from zipfile import ZipFile
with ZipFile(project_path+'train.zip', 'r') as z:
  z.extractall()

"""Repeat the same step for test.zip"""

from zipfile import ZipFile
with ZipFile(project_path+'test.zip', 'r') as z:
  z.extractall()

"""Repeat the same step for sample_submission.csv.zip"""

from zipfile import ZipFile
with ZipFile(project_path+'sample_submission.csv.zip', 'r') as z:
  z.extractall()

"""Repeat the same step for labels.csv.zip"""

from zipfile import ZipFile
with ZipFile(project_path+'labels.csv.zip', 'r') as z:
  z.extractall()

"""After this process, we will have 4 files - Train folder, test folder and labels.csv and sample_submission.csv as part of your google drive

### Read labels.csv file using pandas
"""

labels = pd.read_csv('/content/labels.csv')

"""### Print the count of each category of Dogs given in the dataset"""

labels.head()

labels.breed.value_counts()

"""### Get one-hot encodings of labels"""

targets = pd.Series(labels.breed)

one_hot = pd.get_dummies(targets, sparse = True)

one_hot_labels = np.asarray(one_hot)

one_hot_labels[0]

one_hot_labels[0].shape

le = LabelEncoder()
integer_encoded = le.fit_transform(labels.breed)
print(integer_encoded)

import keras
y = tf.keras.utils.to_categorical(integer_encoded, num_classes = None, dtype = 'int')

y[0]

"""## Preparing training dataset
1. Write a code which reads each and every id from labels.csv file and loads the corresponding image (in RGB - 128, 128, 3) from the train folder. <br>
2. Create 2 variables <br> 
     a.  x_train - Should have all the images of the dogs from train folder <br>
     b.  y_train - Corresponding label of the dog <br>
<u>Note:</u> The id of the dog images and its corresponding labels are available in labels.csv file   
<u>Hint:</u> Watch the video shared on "Preparing the training dataset" if you face issue on creating the training dataset
"""

img_rows = 128
img_cols = 128
x_train_data = []
y_train_data = []

for f, img in tqdm(labels.values): # f for format, jpg
  train_img = cv2.imread('./train/{}.jpg'.format(f),1)
  train_img_resize = cv2.resize(train_img, (img_rows, img_cols))
  x_train_data.append(train_img_resize)
  y_train_data.append(img)

#plotting first 10 images in training sample
plt.figure(figsize=(10,10))
for i in range(10):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(x_train_data[i])
    plt.xlabel([y_train_data[i]])
plt.show()

"""Normalize the training data and convert into 4 dimensions so that it can be used as an input to conv layers in the model"""

#Converting fetched dataset into numpy array of data type float32 for compatibility with Keras
x_train_data_float = np.array(x_train_data).astype('float32')

x_train_data_norm = x_train_data_float/255.0

x_train_data_norm.dtype

x_train_data_norm.shape

le = LabelEncoder()
y_train_le = le.fit_transform(y_train_data)

y_train_cat = tf.keras.utils.to_categorical(y_train_le)

y_train_cat[0]

"""### Split the training and validation data from `x_train_data` and `y_train_data` obtained from above step"""

# split x_train and y_train into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(x_train_data_norm, y_train_cat, test_size=0.25, random_state=2)
print(x_train.shape)
print(x_val.shape)
print(y_train.shape)
print(y_val.shape)

"""### Loading the test data
Read the id column from the samples_submission.csv and store it in test_img
"""

test_data = pd.read_csv('/content/sample_submission.csv')

test_data.head()

test_data.shape

test_img = test_data.id

test_img.values

"""Run the below code to load the test image files in x_test_feature"""

x_test_feature = []
i = 0 # initialisation
for f in tqdm(test_img.values): # f for format ,jpg
    img = cv2.imread('./test/{}.jpg'.format(f), 1)
    img_resize = cv2.resize(img, (img_rows, img_cols)) 
    x_test_feature.append(img_resize)

#plotting first 10 images in training sample
plt.figure(figsize=(10,10))
for i in range(10):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.grid(False)
    plt.imshow(x_test_feature[i])
plt.show()

"""Normalize the test data and convert it into 4 dimensions"""

x_test_feature_float = np.array(x_test_feature).astype('float32')
x_test_feature_norm = x_test_feature_float/255.0
print('dtype of x_test_feature:',x_test_feature_norm.dtype)
print('Shape of x_test_feature: ',x_test_feature_norm.shape)

"""### Build a basic conv neural network with 2 conv layers (kernel sizes - 5 and 3) add layers as mentioned below for classification.

1. Add a Dense layer with 256 neurons with `relu` activation

2. Add a Dense layer with 120 neurons as final layer (as there are 120 classes in the given dataset) with `softmax` activation for classifiaction.
"""

clear_session()
# Initializing the CNN model
model = Sequential()

#normalize data
model.add(BatchNormalization(input_shape=(128,128,3,),name='input'))

#Add first convolutional layer
model.add(Conv2D(32, #Number of filters 
                kernel_size=(5,5), #Size of the filter
                activation='relu', name = 'conv_1'))

#Add second convolutional layer
model.add(Conv2D(64, kernel_size=(3,3), activation='relu', name = 'conv_2'))

#Add Fully Connected Layer with 256 units and activation function as 'ReLU'
model.add(Dense(256, activation='relu',name='dense_1'))

#Flatten the output
model.add(Flatten())

# Adding the output layer using softmax as activation function
model.add(Dense(units=120, activation = 'softmax', name = 'output'))

model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])

model.summary()

"""### Use batch_size = 128 and epochs = 10 and execute the model"""

model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=128, epochs=10)

#Validating the model on validation set
score = model.evaluate(x_val, y_val)
print('Validation loss:', score[0])
print('Validation accuracy:', score[1])

"""#The model accuracy is very poor !!!!

### Use Data Augmentation in the above model to see if the accuracy improves
"""

train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True,
                                                               width_shift_range=0.2,
                                                               height_shift_range=0.2,
                                                               rotation_range=30,
                                                               shear_range=0.2,
                                                               zoom_range=0.3)

val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True,
                                                               width_shift_range=0.2,
                                                               height_shift_range=0.2,
                                                               rotation_range=30,
                                                               shear_range=0.2,
                                                               zoom_range=0.3)

"""### Using the above objects, create the image generators with variable names `train_generator` and `val_generator`

You need to use train_datagen.flow() and val_datagen.flow()
"""

#Build training generator. 
train_generator = train_datagen.flow(x_train, y_train, batch_size=128)

#Build val generator
val_generator = val_datagen.flow(x_val, y_val, batch_size=128)

"""### Fit the model using fit_generator() using `train_generator` and `val_generator` from the above step with 10 epochs"""

#Saving the best model using model checkpoint callback
model_checkpoint=tf.keras.callbacks.ModelCheckpoint('dog_breed.h5', 
                                                    save_best_only=True, 
                                                    monitor='val_accuracy', 
                                                    mode='max', 
                                                    verbose=1)

model.fit_generator(train_generator,
                    epochs=10,
                    steps_per_epoch= x_train.shape[0]//128,  #Number of training images//batch_size
                    validation_data=val_generator,
                    validation_steps = x_val.shape[0]//128, #Number of test images//batch_size
                    callbacks = [model_checkpoint])

#Validating the model on validation set
score = model.evaluate(x_val, y_val)
print('Validation loss:', score[0])
print('Validation accuracy:', score[1])

"""# Model accuracy is still poor!!!

### Lets use Transfer Learning

Download the vgg wieght file from here : https://github.com/MinerKasch/applied_deep_learning/blob/master/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5

Use the below code to load VGG16 weights trained on ImageNet

Defining project path for vgg weight file
"""

project_path_vgg = "/content/drive/My Drive/GreatLearning/myprojects/Residency8/"

from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input
# Instantiate the model with the pre-trained weights (no top)
base_model= VGG16(weights=(project_path_vgg+'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'),
                 include_top=False, input_shape=(224,224,3), pooling='avg')

"""Print the summary of the base_model"""

base_model.summary()

"""From above summary base model, layers are as follows:
Input layer, block1(2 x Conv layer, 1 x MaxPooling) + block2(2 x Conv layer,1 x MaxPooling) + block3(3 x Conv layer,1 x MaxPooling) + block4(3 x Conv layer,1 x MaxPooling) + block5(3 x Conv layer,1 x MaxPooling) + 1 x GlobalAveragePooling.

There are total 14,714,688 Trainable parameters and no Non-trainable parameters

### Add the following classification layers to the imported VGG Model <br>
1. Flatten Layer
2. Dense layer with 1024 neurons with activation as Relu
3. Dense layer with 256 neurons with activation as Relu
4. Dense layer with 120 neurons with activation as Softmax

Storing the output of base model
"""

#get Output layer of Pre-trained model
x = base_model.output

"""Adding flatten and dense layers on top of base model"""

#Add Flatten layer
x = Flatten()(x)

#Add Fully Connected Layer with 1024 units and activation function as 'ReLU'
x = Dense(1024, activation='relu')(x)

#Add Fully Connected Layer with 256 units and activation function as 'ReLU'
x = Dense(256, activation='relu')(x)

# Adding the output layer using softmax as activation function
prediction = Dense(units=120, activation = 'softmax')(x)

"""### Make all the layers in the base_model (VGG16) to be non-trainable

Setting the layers for base_model as non-trainable
"""

#Set pre-trained model layers to not trainable
for layer in base_model.layers:
    layer.trainable = False

"""### Fit and compile the model with batch_size = 128 and epochs = 10 and execute the model

Try to get training and validation accuracy to be more than 90%

Compiling final model
"""

#Using Keras Model class
final_model = tf.keras.models.Model(inputs=base_model.input, #Pre-trained model input as input layer
                                    outputs=prediction) #Output layer added

#Compile the model
final_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

#Summary of final model
final_model.summary()

"""From final model summary, it can be clearly seen that non-trainable parameters is same as total parameters in base model and trainable parameters is sum of paramters in add-on model.

Using model checkpoint callback to save best model
"""

#Saving the best model using model checkpoint callback
model_checkpoint=tf.keras.callbacks.ModelCheckpoint('dog_breed1.h5', 
                                                    save_best_only=True, 
                                                    monitor='val_accuracy', 
                                                    mode='max', 
                                                    verbose=1)

"""Resizing the images for input to VGG16 model (224,224,3)"""

img_rows1 = 224
img_cols1 = 224
x_train1_data = []
y_train1_data = []

for f, img in tqdm(labels.values): # f for format, jpg
  train_img = cv2.imread('./train/{}.jpg'.format(f),1)
  train_img_resize = cv2.resize(train_img, (img_rows1, img_cols1))
  x_train1_data.append(train_img_resize)
  y_train1_data.append(img)

"""Preprocessing of the training data and splitting into training and validation set"""

#Converting fetched dataset into numpy array of data type float32 for compatibility with Keras
x_train1_data_float = np.array(x_train1_data).astype('float32')

x_train1_data_norm = x_train1_data_float/255.0 # Normalizing training data
x_train1_data_norm.dtype
x_train1_data_norm.shape
le = LabelEncoder()
y_train1_le = le.fit_transform(y_train1_data)
y_train1_cat = tf.keras.utils.to_categorical(y_train1_le)
# split x_train1 and y_train1 into training and validation sets
x_train1, x_val1, y_train1, y_val1 = train_test_split(x_train1_data_norm, y_train1_cat, test_size=0.25, random_state=2)

"""Printing shapes of training and validation set"""

print(x_train1.shape)
print(x_val1.shape)
print(y_train1.shape)
print(y_val1.shape)

"""Training the model"""

final_model.fit(x_train1, y_train1, validation_data=(x_val1, y_val1), batch_size=128, epochs=10)

#Validating the model on validation set
training_score = final_model.evaluate(x_train1, y_train1)
print('Training loss:', training_score[0])
print('Training accuracy:', training_score[1])
validation_score = final_model.evaluate(x_val1, y_val1)
print('Validation loss:', validation_score[0])
print('Validation accuracy:', validation_score[1])

"""With batch size of 128 and 10 epochs, training accuracy and validation accuracy is printed above.
Apparently, with more number of epochs, model should learn better and validation accuracy may be improved.

Adding some variations in above model to improve the accuracy.

First checking with increasing epoch to 100 and batch size of 128
"""

#Using Keras Model class
final_model1 = tf.keras.models.Model(inputs=base_model.input, #Pre-trained model input as input layer
                                    outputs=prediction) #Output layer added

#Compile the model
final_model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

final_model1.fit(x_train1, y_train1, validation_data=(x_val1, y_val1), batch_size=128, epochs=100)

"""From above, with 128 batch size and 100 epochs, model seems to overfit as training accuracy is going very high but validation accuracy is significantly less as than training accuracy

To avoid overfitting, adding batch normalization after every dense layer and dropout layer before output layer in the add-on model to base model
"""

#get Output layer of Pre-trained model
x = base_model.output

#Add Flatten layer
x = Flatten()(x)

#Add Fully Connected Layer with 1024 units and activation function as 'ReLU'
x = Dense(1024, activation='relu')(x)

# BatchNormalization layer
x = BatchNormalization()(x)

#Add Fully Connected Layer with 256 units and activation function as 'ReLU'
x = Dense(256, activation='relu')(x)

# BatchNormalization layer
x = BatchNormalization()(x)

#Add Dropout
x = Dropout(0.5)(x)

# Adding the output layer using softmax as activation function
prediction = Dense(units=120, activation = 'softmax')(x)

#Set pre-trained model layers to not trainable
for layer in base_model.layers:
    layer.trainable = False
	
#Using Keras Model class
final_model2 = tf.keras.models.Model(inputs=base_model.input, #Pre-trained model input as input layer
                                    outputs=prediction) #Output layer added
									
#Compile the model
final_model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

#Summary of final model
final_model2.summary()

final_model2.fit(x_train1, y_train1, validation_data=(x_val1, y_val1), batch_size=128, epochs=100)

"""Adding Batch Normalization and Dropout layer as final_model2 does seem to have much effect on overfitting for this dataset.

Trying below additional dropout layer before last dense layers and unfreeze one convolutional layer for training in base model
"""

len(base_model.layers)

base_model.layers[0:5]

"""there are 20 layers in base model

Unfreezing first convolutional layer in base model to have less impact on computational processing as this layer is having least number of trainable parameters.
"""

#get Output layer of Pre-trained model
x = base_model.output

#Add Flatten layer
x = Flatten()(x)

#Add Fully Connected Layer with 1024 units and activation function as 'ReLU'
x = Dense(1024, activation='relu')(x)

# BatchNormalization layer
x = BatchNormalization()(x)

#Add Dropout
x = Dropout(0.5)(x)

#Add Fully Connected Layer with 256 units and activation function as 'ReLU'
x = Dense(256, activation='relu')(x)

# BatchNormalization layer
x = BatchNormalization()(x)

#Add Dropout
x = Dropout(0.5)(x)

# Adding the output layer using softmax as activation function
prediction = Dense(units=120, activation = 'softmax')(x)

#Set pre-trained model layers to not trainable
for layer in base_model.layers:
    layer.trainable = False
    base_model.layers[1].trainable = True

#Using Keras Model class
final_model3 = tf.keras.models.Model(inputs=base_model.input, #Pre-trained model input as input layer
                                    outputs=prediction) #Output layer added
									
#Compile the model
final_model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

#Summary of final model
final_model3.summary()

"""From above summary, it can be confirmed that trainable parameters have increased by 1792 which is the number of params in first convolutional layer in base model"""

final_model3.fit(x_train1, y_train1, validation_data=(x_val1, y_val1), batch_size=128, epochs=50)

"""As an attempt to further improve accuracy, unfreezing only second convolutional layer in next model and increase dense layers (add two dense layers) with batch normalization."""

#get Output layer of Pre-trained model
x = base_model.output

#Add Flatten layer
x = Flatten()(x)

#Add Fully Connected Layer with 1024 units and activation function as 'ReLU'
x = Dense(1024, activation='relu')(x)

# BatchNormalization layer
x = BatchNormalization()(x)

#Add Dropout
x = Dropout(0.5)(x)

#Add Fully Connected Layer with 256 units and activation function as 'ReLU'
x = Dense(256, activation='relu')(x)

# BatchNormalization layer
x = BatchNormalization()(x)

#Add Fully Connected Layer with 64 units and activation function as 'ReLU'
x = Dense(64, activation='relu')(x)

# BatchNormalization layer
x = BatchNormalization()(x)

#Add Dropout
x = Dropout(0.5)(x)

# Adding the output layer using softmax as activation function
prediction = Dense(units=120, activation = 'softmax')(x)

#Set pre-trained model layers to not trainable
for layer in base_model.layers:
    layer.trainable = False
    base_model.layers[2].trainable = True

#Using Keras Model class
final_model4 = tf.keras.models.Model(inputs=base_model.input, #Pre-trained model input as input layer
                                    outputs=prediction) #Output layer added
									
#Compile the model
final_model4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

#Summary of final model
final_model4.summary()

"""From above summary, trainable parameters has been increased to 36928 due to unfreezing of second convolutional layer in base model."""

final_model4.fit(x_train1, y_train1, validation_data=(x_val1, y_val1), batch_size=128, epochs=10)

final_model4.fit(x_train1, y_train1, validation_data=(x_val1, y_val1), batch_size=128, epochs=20)

"""Above model (final_model4) looks better so far with less sign of overfitting and good convergence of validation accuracy

Unfreezing last convolutional layer in base model
"""

#get Output layer of Pre-trained model
x = base_model.output

#Add Flatten layer
x = Flatten()(x)

#Add Fully Connected Layer with 1024 units and activation function as 'ReLU'
x = Dense(1024, activation='relu')(x)

# BatchNormalization layer
x = BatchNormalization()(x)

#Add Fully Connected Layer with 256 units and activation function as 'ReLU'
x = Dense(256, activation='relu')(x)

# BatchNormalization layer
x = BatchNormalization()(x)

#Add Dropout
x = Dropout(0.5)(x)

# Adding the output layer using softmax as activation function
prediction = Dense(units=120, activation = 'softmax')(x)

#Set pre-trained model layers to not trainable
for layer in base_model.layers:
    layer.trainable = False
    base_model.layers[17].trainable = True

base_model.layers[15:]

#Using Keras Model class
final_model5 = tf.keras.models.Model(inputs=base_model.input, #Pre-trained model input as input layer
                                    outputs=prediction) #Output layer added
									
#Compile the model
final_model5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

#Summary of final model
final_model5.summary()

final_model5.fit(x_train1, y_train1, validation_data=(x_val1, y_val1), batch_size=128, epochs=10)

final_model5.fit(x_train1, y_train1, validation_data=(x_val1, y_val1), batch_size=128, epochs=50)

"""final_model5 looks highly overfitted

Trying further epochs for training previous model final_model4 as that model is best so far with less overfitting and good validation accuracy with less number of epochs
"""

final_model4.fit(x_train1, y_train1, validation_data=(x_val1, y_val1), batch_size=128, epochs=70)

"""Summary:
========

model - basic CNN  ----> very poor accuracy

model - CNN with data augmentation ----> very poor accuracy

final_model - transfer learning VGG16 + add-on model ----> slight improvement but still poor accuracy

final_model1 - transfer learning VGG16 + add-on model (batch normalization + dropout layer) ---> not much gain in accuracy from final_model

final_model2 - transfer learning VGG16 + add-on model (batch normalization + increased dropout layer) ----> not much gain in accuracy from final_model but highly overfitted

final_model3 - transfer learning VGG16 + add-on model (batch normalization + dropout layers) + unfreezed first convolutional layer in base model  ---> some improvement in accuracy from final_model2 but significant overfitting

final_model4 - transfer learning VGG16 + add-on model (added on dense layer + batch normalization + dropout layers) + unfreezed second convolutional layer in base model ---> looks better so far with less sign of overfitting and good convergence of validation accuracy

final_model5 - transfer learning VGG16 + add-on model (added on dense layer + batch normalization + dropout layers) + unfreezed last convolutional layer in base model  ---> highly overfitted not much improvement in validation accuracy from final_model4
"""